1.线性回归
应用领域：预测价格等
已知输入参数x，通过线性函数y=ax+b来预测y
根据给定结果集来训练得到最佳参数a,b
代价函数：
J = 
for(结果集)
{
  J +  (a*a[i] + b - y[i])的平方
}

求最小的J的参数a和b
最后得到预测函数y=ax+b



1.逻辑回归
应用于处理分类问题:垃圾邮件，肿瘤判断
给定结果集y: 要么0，要么1

sigmod函数：
h(x) = 1/(1+e 的-(ax+b)次方)
a,b是待训练的参数
把要预测的x带入h(x)，当结果大于0.5则预测y=1,当结果小于0.5则y=0

训练过程:
代价函数:
if y=1:
cost(h(x),y) = -log(h(x));   //这个函数使得当h(x)无限靠近1的时候代价函数无限接近0
if y=0:
cost(h(x),y) = -log(1-h(x)); //这个函数使得当h(x)无限靠近0的时候代价函数无限接近0

拼成数学公式：
cost(h(x),y) = -ylog(h(x)) - (1-y)log(1-h(x));

J = 求和(cost(h(x),y)/m);
然后求最小的J。得到最佳的a,b




